{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufaGO83dTat7",
        "outputId": "56f05dc9-cd27-4503-e822-a7f244a9a29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m112.6/126.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.2.2)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from textblob import TextBlob\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import random\n",
        "import re\n",
        "import spacy\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "# Ensure required nltk data is downloaded\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "#nltk.download('maxent_ne_chunker')\n",
        "#nltk.download('words')\n",
        "\n",
        "class CommentGenerator:\n",
        "    def __init__(self):\n",
        "        self.analyzer = SentimentIntensityAnalyzer()\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    def analyze_sentiment(self, text):\n",
        "        \"\"\"\n",
        "        Analyzes the sentiment of the given text.\n",
        "        Returns:\n",
        "            - Sentiment: ('positive', 'neutral', 'negative')\n",
        "        \"\"\"\n",
        "        sentiment_scores = self.analyzer.polarity_scores(text)\n",
        "        sentiment = sentiment_scores['compound']\n",
        "\n",
        "        if sentiment >= 0.05:\n",
        "            return 'positive'\n",
        "        elif sentiment <= -0.05:\n",
        "            return 'negative'\n",
        "        else:\n",
        "            return 'neutral'\n",
        "\n",
        "    def analyze_tone(self, text):\n",
        "        \"\"\"\n",
        "        Analyzes the tone of the given text.\n",
        "        Returns:\n",
        "            - Tone: ('friendly', 'funny', 'congratulating', 'questioning', 'disagreement')\n",
        "        Using keyword detection\"\"\"\n",
        "        positive_keywords = ['great', 'fantastic', 'excellent', 'good', 'amazing', 'wonderful']\n",
        "        funny_keywords = ['haha', 'lol', 'funny', 'hilarious', 'joke', 'humor']\n",
        "        congratulating_keywords = ['congratulations', 'kudos', 'well done', 'bravo', 'praise']\n",
        "        questioning_keywords = ['why', 'how', 'what', 'question', 'curious', 'wonder']\n",
        "        disagreement_keywords = ['disagree', 'wrong', 'not', 'no', 'incorrect', 'however']\n",
        "\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        def contains_keywords(keywords):\n",
        "            return any(re.search(r'\\b' + keyword + r'\\b', text_lower) for keyword in keywords)\n",
        "\n",
        "        if contains_keywords(positive_keywords):\n",
        "            return 'friendly'\n",
        "        elif contains_keywords(funny_keywords):\n",
        "            return 'funny'\n",
        "        elif contains_keywords(congratulating_keywords):\n",
        "            return 'congratulating'\n",
        "        elif contains_keywords(questioning_keywords):\n",
        "            return 'questioning'\n",
        "        elif contains_keywords(disagreement_keywords):\n",
        "            return 'disagreement'\n",
        "        else:\n",
        "            # Fallback to sentiment-based tone if no specific keywords are found\n",
        "            sentiment = self.analyze_sentiment(text)\n",
        "            if sentiment == 'positive':\n",
        "                return random.choice(['friendly', 'congratulating'])\n",
        "            elif sentiment == 'negative':\n",
        "                return 'disagreement'\n",
        "            else:\n",
        "                return random.choice(['funny', 'questioning'])\n",
        "\n",
        "    def extract_entities(self, text):\n",
        "        \"\"\"\n",
        "        Extracts named entities from the text.\n",
        "        Returns:\n",
        "            - entities: List of named entities\n",
        "        Using Spacy's NER capabibilities\"\"\"\n",
        "        doc = self.nlp(text)\n",
        "        entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"EVENT\", \"PRODUCT\", \"WORK_OF_ART\", \"LANGUAGE\"]]\n",
        "        return entities\n",
        "\n",
        "    def summarize_text(self, text):\n",
        "        \"\"\"\n",
        "        Summarizes the given text.\n",
        "        Returns:\n",
        "            - summary: Summarized text\n",
        "        \"\"\"\n",
        "        parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "        summarizer = LsaSummarizer()\n",
        "        summary = summarizer(parser.document, sentences_count=2)\n",
        "        return \" \".join(str(sentence) for sentence in summary)\n",
        "\n",
        "    def generate_comments(self, text):\n",
        "        \"\"\"\n",
        "        Generates five different types of comments based on the given text.\n",
        "        Returns:\n",
        "            - comments: A dictionary containing five types of comments\n",
        "        \"\"\"\n",
        "        tone = self.analyze_tone(text)\n",
        "        sentiment = self.analyze_sentiment(text)\n",
        "        entities = self.extract_entities(text)\n",
        "        summary = self.summarize_text(text)\n",
        "\n",
        "        # Predefined comments with placeholders for entities\n",
        "        friendly_comments = [\n",
        "            \"Great job on covering {}! This article is really insightful and well-written.\",\n",
        "            \"I loved reading this about {}. Keep up the good work!\",\n",
        "            \"This is fantastic! Thanks for sharing about {}.\"\n",
        "        ]\n",
        "\n",
        "        funny_comments = [\n",
        "            \"Haha, the part about {} made my day! Can't stop laughing.\",\n",
        "            \"This is hilarious! Well done on {}!\",\n",
        "            \"Loved the humor in this piece about {}!\"\n",
        "        ]\n",
        "\n",
        "        congratulating_comments = [\n",
        "            \"Congratulations on writing such an engaging piece about {}!\",\n",
        "            \"Well done! This deserves praise, especially about {}.\",\n",
        "            \"Kudos for this excellent article about {}!\"\n",
        "        ]\n",
        "\n",
        "        questioning_comments = [\n",
        "            \"I'm curious about something in this article regarding {}: [Insert question here]\",\n",
        "            \"Could you elaborate more on this point about {}?\",\n",
        "            \"I have a question regarding your argument on {}.\"\n",
        "        ]\n",
        "\n",
        "        disagreement_comments = [\n",
        "            \"I respectfully disagree with some points about {} in this article. Let's discuss further.\",\n",
        "            \"I have a different perspective on this topic, especially about {}.\",\n",
        "            \"Interesting article, but I don't fully agree with some of the points made about {}.\"\n",
        "        ]\n",
        "\n",
        "        # Select a random comment and insert entities if available\n",
        "        entity_str = \", \".join(entities) if entities else \"the topic\"\n",
        "        comments = {\n",
        "            'friendly': random.choice(friendly_comments).format(entity_str),\n",
        "            'funny': random.choice(funny_comments).format(entity_str),\n",
        "            'congratulating': random.choice(congratulating_comments).format(entity_str),\n",
        "            'questioning': random.choice(questioning_comments).format(entity_str),\n",
        "            'disagreement': random.choice(disagreement_comments).format(entity_str)\n",
        "        }\n",
        "\n",
        "        return comments\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    generator = CommentGenerator()\n",
        "    article = input(\"Enter the article: \")\n",
        "    tone = generator.analyze_tone(article)\n",
        "    sentiment = generator.analyze_sentiment(article)\n",
        "    print(\"Tone:\", tone)\n",
        "    print(\"Sentiment:\", sentiment)\n",
        "    comments = generator.generate_comments(article)\n",
        "    print(\"Generated Comments:\")\n",
        "    for comment_type, comment in comments.items():\n",
        "        print(f\"{comment_type.capitalize()}: {comment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqnWZAAC76YP",
        "outputId": "7eadbdcc-23f1-4190-8115-43ac2a7daa98"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the article: You get one, precious life. How do you decide the best way to spend your time? Productivity gurus will often suggest that you focus on being effective rather than being efficient.  Efficiency is about getting more things done. Effectiveness is about getting the right things done. Peter Drucker, the well-known management consultant, once encapsulated the idea by writing, “There is nothing so useless as doing efficiently that which should not be done at all.”  In other words, making progress is not just about being productive. It’s about being productive on the right things.  But how do you decide what the “right things” are? One of the most trusted approaches is to use the Pareto Principle, which is more commonly known as the 80/20 Rule.  The 80/20 Rule states that, in any particular domain, a small number of things account for the majority of the results. For example, 80 percent of the land in Italy is owned by 20 percent of the people. Or, 75 percent of NBA championships are won by 20 percent of the teams. The numbers don’t have to add up to 100. The point is that the majority of the results are driven by a minority of causes.\n",
            "Tone: questioning\n",
            "Sentiment: positive\n",
            "Generated Comments:\n",
            "Friendly: Great job on covering Peter Drucker, the Pareto Principle, the 80/20 Rule, The 80/20 Rule, Italy, NBA! This article is really insightful and well-written.\n",
            "Funny: This is hilarious! Well done on Peter Drucker, the Pareto Principle, the 80/20 Rule, The 80/20 Rule, Italy, NBA!\n",
            "Congratulating: Kudos for this excellent article about Peter Drucker, the Pareto Principle, the 80/20 Rule, The 80/20 Rule, Italy, NBA!\n",
            "Questioning: I'm curious about something in this article regarding Peter Drucker, the Pareto Principle, the 80/20 Rule, The 80/20 Rule, Italy, NBA: [Insert question here]\n",
            "Disagreement: Interesting article, but I don't fully agree with some of the points made about Peter Drucker, the Pareto Principle, the 80/20 Rule, The 80/20 Rule, Italy, NBA.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from textblob import TextBlob\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import random\n",
        "import re\n",
        "import spacy\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "# Ensure required nltk data is downloaded\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "#nltk.download('maxent_ne_chunker')\n",
        "#nltk.download('words')\n",
        "\n",
        "class CommentGenerator:\n",
        "    def __init__(self):\n",
        "        self.analyzer = SentimentIntensityAnalyzer()\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    def analyze_sentiment(self, text):\n",
        "        \"\"\"\n",
        "        Analyzes the sentiment of the given text.\n",
        "        Returns:\n",
        "            - Sentiment: ('positive', 'neutral', 'negative')\n",
        "        \"\"\"\n",
        "        sentiment_scores = self.analyzer.polarity_scores(text)\n",
        "        sentiment = sentiment_scores['compound']\n",
        "\n",
        "        if sentiment >= 0.05:\n",
        "            return 'positive'\n",
        "        elif sentiment <= -0.05:\n",
        "            return 'negative'\n",
        "        else:\n",
        "            return 'neutral'\n",
        "\n",
        "    def analyze_tone(self, text):\n",
        "        \"\"\"\n",
        "        Analyzes the tone of the given text.\n",
        "        Returns:\n",
        "            - Tone: ('friendly', 'funny', 'congratulating', 'questioning', 'disagreement')\n",
        "        \"\"\"\n",
        "        positive_keywords = ['great', 'fantastic', 'excellent', 'good', 'amazing', 'wonderful']\n",
        "        funny_keywords = ['haha', 'lol', 'funny', 'hilarious', 'joke', 'humor']\n",
        "        congratulating_keywords = ['congratulations', 'kudos', 'well done', 'bravo', 'praise']\n",
        "        questioning_keywords = ['why', 'how', 'what', 'question', 'curious', 'wonder']\n",
        "        disagreement_keywords = ['disagree', 'wrong', 'not', 'no', 'incorrect', 'however']\n",
        "\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        def contains_keywords(keywords):\n",
        "            return any(re.search(r'\\b' + keyword + r'\\b', text_lower) for keyword in keywords)\n",
        "\n",
        "        if contains_keywords(positive_keywords):\n",
        "            return 'friendly'\n",
        "        elif contains_keywords(funny_keywords):\n",
        "            return 'funny'\n",
        "        elif contains_keywords(congratulating_keywords):\n",
        "            return 'congratulating'\n",
        "        elif contains_keywords(questioning_keywords):\n",
        "            return 'questioning'\n",
        "        elif contains_keywords(disagreement_keywords):\n",
        "            return 'disagreement'\n",
        "        else:\n",
        "            # Fallback to sentiment-based tone if no specific keywords are found\n",
        "            sentiment = self.analyze_sentiment(text)\n",
        "            if sentiment == 'positive':\n",
        "                return random.choice(['friendly', 'congratulating'])\n",
        "            elif sentiment == 'negative':\n",
        "                return 'disagreement'\n",
        "            else:\n",
        "                return random.choice(['funny', 'questioning'])\n",
        "\n",
        "    def extract_entities(self, text):\n",
        "        \"\"\"\n",
        "        Extracts named entities from the text.\n",
        "        Returns:\n",
        "            - entities: List of named entities\n",
        "        \"\"\"\n",
        "        doc = self.nlp(text)\n",
        "        entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"EVENT\", \"PRODUCT\", \"WORK_OF_ART\", \"LANGUAGE\"]]\n",
        "        return entities\n",
        "\n",
        "    def summarize_text(self, text):\n",
        "        \"\"\"\n",
        "        Summarizes the given text.\n",
        "        Returns:\n",
        "            - summary: Summarized text\n",
        "        \"\"\"\n",
        "        parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "        summarizer = LsaSummarizer()\n",
        "        summary = summarizer(parser.document, sentences_count=2)\n",
        "        return \" \".join(str(sentence) for sentence in summary)\n",
        "\n",
        "    def generate_comments(self, text):\n",
        "        \"\"\"\n",
        "        Generates five different types of comments based on the given text.\n",
        "        Returns:\n",
        "            - comments: A dictionary containing five types of comments\n",
        "        \"\"\"\n",
        "        tone = self.analyze_tone(text)\n",
        "        sentiment = self.analyze_sentiment(text)\n",
        "        entities = self.extract_entities(text)\n",
        "        summary = self.summarize_text(text)\n",
        "\n",
        "        # Predefined comments with placeholders for entities\n",
        "        friendly_comments = [\n",
        "            \"Great job on covering {}! This article is really insightful and well-written.\",\n",
        "            \"I loved reading this about {}. Keep up the good work!\",\n",
        "            \"This is fantastic! Thanks for sharing about {}.\"\n",
        "        ]\n",
        "\n",
        "        funny_comments = [\n",
        "            \"Haha, the part about {} made my day! Can't stop laughing.\",\n",
        "            \"This is hilarious! Well done on {}!\",\n",
        "            \"Loved the humor in this piece about {}!\"\n",
        "        ]\n",
        "\n",
        "        congratulating_comments = [\n",
        "            \"Congratulations on writing such an engaging piece about {}!\",\n",
        "            \"Well done! This deserves praise, especially about {}.\",\n",
        "            \"Kudos for this excellent article about {}!\"\n",
        "        ]\n",
        "\n",
        "        questioning_comments = [\n",
        "            \"I'm curious about something in this article regarding {}: [Insert question here]\",\n",
        "            \"Could you elaborate more on this point about {}?\",\n",
        "            \"I have a question regarding your argument on {}.\"\n",
        "        ]\n",
        "\n",
        "        disagreement_comments = [\n",
        "            \"I respectfully disagree with some points about {} in this article. Let's discuss further.\",\n",
        "            \"I have a different perspective on this topic, especially about {}.\",\n",
        "            \"Interesting article, but I don't fully agree with some of the points made about {}.\"\n",
        "        ]\n",
        "\n",
        "        # Select a random comment and insert entities if available\n",
        "        entity_str = \", \".join(entities) if entities else \"the topic\"\n",
        "        comments = {\n",
        "            'friendly': random.choice(friendly_comments).format(entity_str),\n",
        "            'funny': random.choice(funny_comments).format(entity_str),\n",
        "            'congratulating': random.choice(congratulating_comments).format(entity_str),\n",
        "            'questioning': random.choice(questioning_comments).format(entity_str),\n",
        "            'disagreement': random.choice(disagreement_comments).format(entity_str)\n",
        "        }\n",
        "\n",
        "        return comments\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    generator = CommentGenerator()\n",
        "    article = input(\"Enter the article: \")\n",
        "    tone = generator.analyze_tone(article)\n",
        "    sentiment = generator.analyze_sentiment(article)\n",
        "    print(\"Tone:\", tone)\n",
        "    print(\"Sentiment:\", sentiment)\n",
        "    comments = generator.generate_comments(article)\n",
        "    print(\"Generated Comments:\")\n",
        "    for comment_type, comment in comments.items():\n",
        "        print(f\"{comment_type.capitalize()}: {comment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMXLOO0g-SbH",
        "outputId": "44fa93fb-4611-49b7-d1e4-70ca1dd7e2fc"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the article: When my friend Beck Tench began her weight loss journey, she repeatedly asked herself the question, “What would a healthy person do?”  When she was deciding what to order a restaurant: what would a healthy person order? When she was sitting around on a Saturday morning: what would a healthy person do with that time? Beck didn’t feel like a healthy person at the start, but she figured that if she acted like a healthy person, then eventually she would become one. And within a few years, she had lost over 100 pounds.  Confidence is a wonderful thing to have, but if you find yourself overcome with fear, self-doubt, or uncertainty, then let your behavior drive your beliefs. Play as if you’re at your best. Work as if you’re on top of your game. Talk to that person as if you’re feeling confident. You can use bold actions to trigger a bold mindset.\n",
            "Tone: friendly\n",
            "Sentiment: positive\n",
            "Generated Comments:\n",
            "Friendly: I loved reading this about Beck Tench. Keep up the good work!\n",
            "Funny: Loved the humor in this piece about Beck Tench!\n",
            "Congratulating: Kudos for this excellent article about Beck Tench!\n",
            "Questioning: Could you elaborate more on this point about Beck Tench?\n",
            "Disagreement: Interesting article, but I don't fully agree with some of the points made about Beck Tench.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from textblob import TextBlob\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import random\n",
        "import re\n",
        "import spacy\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "# Ensure required nltk data is downloaded\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "#nltk.download('maxent_ne_chunker')\n",
        "#nltk.download('words')\n",
        "\n",
        "class CommentGenerator:\n",
        "    def __init__(self):\n",
        "        self.analyzer = SentimentIntensityAnalyzer()\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    def analyze_sentiment(self, text):\n",
        "        \"\"\"\n",
        "        Analyzes the sentiment of the given text.\n",
        "        Returns:\n",
        "            - Sentiment: ('positive', 'neutral', 'negative')\n",
        "        \"\"\"\n",
        "        sentiment_scores = self.analyzer.polarity_scores(text)\n",
        "        sentiment = sentiment_scores['compound']\n",
        "\n",
        "        if sentiment >= 0.05:\n",
        "            return 'positive'\n",
        "        elif sentiment <= -0.05:\n",
        "            return 'negative'\n",
        "        else:\n",
        "            return 'neutral'\n",
        "\n",
        "    def analyze_tone(self, text):\n",
        "        \"\"\"\n",
        "        Analyzes the tone of the given text.\n",
        "        Returns:\n",
        "            - Tone: ('friendly', 'funny', 'congratulating', 'questioning', 'disagreement')\n",
        "        \"\"\"\n",
        "        positive_keywords = ['great', 'fantastic', 'excellent', 'good', 'amazing', 'wonderful']\n",
        "        funny_keywords = ['haha', 'lol', 'funny', 'hilarious', 'joke', 'humor']\n",
        "        congratulating_keywords = ['congratulations', 'kudos', 'well done', 'bravo', 'praise']\n",
        "        questioning_keywords = ['why', 'how', 'what', 'question', 'curious', 'wonder']\n",
        "        disagreement_keywords = ['disagree', 'wrong', 'not', 'no', 'incorrect', 'however']\n",
        "\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        def contains_keywords(keywords):\n",
        "            return any(re.search(r'\\b' + keyword + r'\\b', text_lower) for keyword in keywords)\n",
        "\n",
        "        if contains_keywords(positive_keywords):\n",
        "            return 'friendly'\n",
        "        elif contains_keywords(funny_keywords):\n",
        "            return 'funny'\n",
        "        elif contains_keywords(congratulating_keywords):\n",
        "            return 'congratulating'\n",
        "        elif contains_keywords(questioning_keywords):\n",
        "            return 'questioning'\n",
        "        elif contains_keywords(disagreement_keywords):\n",
        "            return 'disagreement'\n",
        "        else:\n",
        "            # Fallback to sentiment-based tone if no specific keywords are found\n",
        "            sentiment = self.analyze_sentiment(text)\n",
        "            if sentiment == 'positive':\n",
        "                return random.choice(['friendly', 'congratulating'])\n",
        "            elif sentiment == 'negative':\n",
        "                return 'disagreement'\n",
        "            else:\n",
        "                return random.choice(['funny', 'questioning'])\n",
        "\n",
        "    def extract_entities(self, text):\n",
        "        \"\"\"\n",
        "        Extracts named entities from the text.\n",
        "        Returns:\n",
        "            - entities: List of named entities\n",
        "        \"\"\"\n",
        "        doc = self.nlp(text)\n",
        "        entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"EVENT\", \"PRODUCT\", \"WORK_OF_ART\", \"LANGUAGE\"]]\n",
        "        return entities\n",
        "\n",
        "    def summarize_text(self, text):\n",
        "        \"\"\"\n",
        "        Summarizes the given text.\n",
        "        Returns:\n",
        "            - summary: Summarized text\n",
        "        \"\"\"\n",
        "        parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "        summarizer = LsaSummarizer()\n",
        "        summary = summarizer(parser.document, sentences_count=2)\n",
        "        return \" \".join(str(sentence) for sentence in summary)\n",
        "\n",
        "    def generate_comments(self, text):\n",
        "        \"\"\"\n",
        "        Generates five different types of comments based on the given text.\n",
        "        Returns:\n",
        "            - comments: A dictionary containing five types of comments\n",
        "        \"\"\"\n",
        "        tone = self.analyze_tone(text)\n",
        "        sentiment = self.analyze_sentiment(text)\n",
        "        entities = self.extract_entities(text)\n",
        "        summary = self.summarize_text(text)\n",
        "\n",
        "        # Predefined comments with placeholders for entities\n",
        "        friendly_comments = [\n",
        "            \"Great job on covering {}! This article is really insightful and well-written.\",\n",
        "            \"I loved reading this about {}. Keep up the good work!\",\n",
        "            \"This is fantastic! Thanks for sharing about {}.\"\n",
        "        ]\n",
        "\n",
        "        funny_comments = [\n",
        "            \"Haha, the part about {} made my day! Can't stop laughing.\",\n",
        "            \"This is hilarious! Well done on {}!\",\n",
        "            \"Loved the humor in this piece about {}!\"\n",
        "        ]\n",
        "\n",
        "        congratulating_comments = [\n",
        "            \"Congratulations on writing such an engaging piece about {}!\",\n",
        "            \"Well done! This deserves praise, especially about {}.\",\n",
        "            \"Kudos for this excellent article about {}!\"\n",
        "        ]\n",
        "\n",
        "        questioning_comments = [\n",
        "            \"I'm curious about something in this article regarding {}: [Insert question here]\",\n",
        "            \"Could you elaborate more on this point about {}?\",\n",
        "            \"I have a question regarding your argument on {}.\"\n",
        "        ]\n",
        "\n",
        "        disagreement_comments = [\n",
        "            \"I respectfully disagree with some points about {} in this article. Let's discuss further.\",\n",
        "            \"I have a different perspective on this topic, especially about {}.\",\n",
        "            \"Interesting article, but I don't fully agree with some of the points made about {}.\"\n",
        "        ]\n",
        "\n",
        "        # Select a random comment and insert entities if available\n",
        "        entity_str = \", \".join(entities) if entities else \"the topic\"\n",
        "        comments = {\n",
        "            'friendly': random.choice(friendly_comments).format(entity_str),\n",
        "            'funny': random.choice(funny_comments).format(entity_str),\n",
        "            'congratulating': random.choice(congratulating_comments).format(entity_str),\n",
        "            'questioning': random.choice(questioning_comments).format(entity_str),\n",
        "            'disagreement': random.choice(disagreement_comments).format(entity_str)\n",
        "        }\n",
        "\n",
        "        return comments\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    generator = CommentGenerator()\n",
        "    article = input(\"Enter the article: \")\n",
        "    tone = generator.analyze_tone(article)\n",
        "    sentiment = generator.analyze_sentiment(article)\n",
        "    print(\"Tone:\", tone)\n",
        "    print(\"Sentiment:\", sentiment)\n",
        "    comments = generator.generate_comments(article)\n",
        "    print(\"Generated Comments:\")\n",
        "    for comment_type, comment in comments.items():\n",
        "        print(f\"{comment_type.capitalize()}: {comment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqq8hFeYASIx",
        "outputId": "36d6c39b-4285-4a3c-f37b-1e513bc6e3ee"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the article: How can we apply the growth mindset to creativity in practical terms? In my experience, it comes down to one thing: the willingness to look bad when pursuing an activity.  As Dweck says, the growth mindset is focused more on the process than the outcome. This is easy to accept in theory, but very hard to stick to in practice. Most people don’t want to deal with the accompanying embarrassment or shame that is often required to learn a new skill.  The list of mistakes that you can never recover from is very short. I think most of us realize this on some level. We know that our lives will not be destroyed if that book we write doesn’t sell or if we get turned down by a potential date or if we forget someone’s name when we introduce them. It’s not necessarily what comes after the event that worries us. It’s the possibility of looking stupid, feeling humiliated, or dealing with embarrassment along the way that prevents us from getting started at all.  In order to fully embrace the growth mindset and enhance your creativity, you need to be willing to take action in the face of these feelings which so often deter us.\n",
            "Tone: questioning\n",
            "Sentiment: negative\n",
            "Generated Comments:\n",
            "Friendly: I loved reading this about Dweck. Keep up the good work!\n",
            "Funny: Loved the humor in this piece about Dweck!\n",
            "Congratulating: Congratulations on writing such an engaging piece about Dweck!\n",
            "Questioning: I'm curious about something in this article regarding Dweck: [Insert question here]\n",
            "Disagreement: Interesting article, but I don't fully agree with some of the points made about Dweck.\n"
          ]
        }
      ]
    }
  ]
}